<<<<<<< HEAD
# ðŸš¨ Lima Segura: Sistema de Alerta de Delitos y Zonas Peligrosas

Â¡Bienvenido al repositorio de **Lima Segura**! Este proyecto es una soluciÃ³n tecnolÃ³gica enfocada en el monitoreo, anÃ¡lisis y geolocalizaciÃ³n de la criminalidad en Lima Metropolitana, utilizando **Web Scraping** y **Ciencia de Datos**.

---

## ðŸ“– DescripciÃ³n del Proyecto

La inseguridad ciudadana es uno de los mayores desafÃ­os en Lima. Este proyecto automatiza la recolecciÃ³n de noticias policiales de los principales medios digitales del paÃ­s (RPP, El Comercio, La RepÃºblica) para:

1.  **Centralizar la informaciÃ³n** en tiempo real.
2.  **Geolocalizar incidentes** mediante procesamiento de texto (NLP).
3.  **Visualizar zonas de riesgo** en un mapa interactivo para la ciudadanÃ­a.

---

## ðŸš€ AplicaciÃ³n en Vivo

Nuestra soluciÃ³n estÃ¡ desplegada como un dashboard interactivo usando Streamlit. Puedes explorar los mapas de calor y las Ãºltimas noticias aquÃ­:

**âž¡ï¸ [Accede al dashboard de Lima Segura aquÃ­](https://lp-teoriatrabajofinal-npgerz4t2krxgad8b83fux.streamlit.app/)**


<br>

---


## ðŸ› ï¸ TecnologÃ­as Utilizadas

Este proyecto fue construido integrando diversas herramientas de Data Science y Desarrollo Web:

* **Python ðŸ:** Lenguaje principal para todo el backend y lÃ³gica.
* **Streamlit ðŸŽˆ:** Framework para la creaciÃ³n del dashboard web interactivo.
* **BeautifulSoup & Requests ðŸ•·ï¸:** Para el Web Scraping automatizado de noticias.
* **Pandas ðŸ¼:** Limpieza, estructuraciÃ³n y anÃ¡lisis de los datos extraÃ­dos.
* **Pydeck & Mapbox ðŸ—ºï¸:** Para la visualizaciÃ³n geoespacial avanzada (mapas oscuros y capas de calor).
* **GitHub:** Control de versiones y colaboraciÃ³n.

---

## ðŸ‘¥ El Equipo

Proyecto desarrollado por estudiantes de **IngenierÃ­a EstadÃ­stica e InformÃ¡tica - UNALM**:

* **Daniel OrmeÃ±o Sakihama** - [GitHub](https://github.com/Orsaki)
* **Luis Huamayalli** - [GitHub](https://github.com/Albert-ca)
* **Pamela LÃ¡zaro** - [GitHub](https://github.com/lazaropamela)
* **FÃ¡tima Montes** - [GitHub](https://github.com/FatimaMY)

---
=======
# ðŸ“‚ Web Scraping â€“ RecolecciÃ³n de Noticias de Inseguridad en Lima

## ðŸ“Œ DescripciÃ³n general

Este mÃ³dulo contiene los scripts encargados de la **recolecciÃ³n automatizada de noticias relacionadas con inseguridad ciudadana en Lima Metropolitana**, a partir de distintos medios digitales peruanos.  
El objetivo es **construir una base de datos unificada de noticias policiales**, que luego serÃ¡ procesada para su anÃ¡lisis geoespacial y visualizaciÃ³n en un mapa interactivo.

---

## ðŸ“° Fuentes de informaciÃ³n

Las noticias se obtienen mediante **Web Scraping y feeds RSS** desde medios periodÃ­sticos de reconocida trayectoria en el PerÃº:

- **El Comercio** â€“ secciÃ³n Judiciales / Lima  
- **La RepÃºblica** â€“ secciÃ³n Sociedad  
- **RPP Noticias** â€“ Ãšltimas noticias / Seguridad  
- **PerÃº21** â€“ secciÃ³n Lima  
- **Diario Correo** â€“ secciÃ³n PerÃº  
- **Infobae PerÃº** â€“ portada PerÃº  

> Estas fuentes fueron seleccionadas por su **confiabilidad periodÃ­stica**, **actualizaciÃ³n constante** y **estructura web adecuada para la extracciÃ³n automatizada de datos**.

---

## ðŸ”Ž Criterios de filtrado

Para identificar Ãºnicamente noticias relacionadas con delitos e inseguridad, se aplica un **filtro por palabras clave** sobre los tÃ­tulos de las noticias, tales como:
**robo, asalto, delincuencia, crimen, policÃ­a, sicario, balacera, asesinato, extorsiÃ³n, captura**


Este enfoque permite **reducir ruido informativo** y enfocarse exclusivamente en eventos relevantes para el anÃ¡lisis.

---

## âš™ï¸ TecnologÃ­as utilizadas

- **Python**
- **Requests**
- **BeautifulSoup**
- **Pandas**
- **CSV**
- **RSS Feeds**

---

## ðŸ“ Estructura del mÃ³dulo

```
webscraping/
â”‚
â”œâ”€â”€ scraping_elcomercio.py
â”œâ”€â”€ scraping_larepublica.py
â”œâ”€â”€ scraping_rpp.py
â”œâ”€â”€ scraping_peru21.py
â”œâ”€â”€ scraping_diariocorreo.py
â”œâ”€â”€ scraping_infobae.py
â”‚
â”œâ”€â”€ noticias_elcomercio_filtradas.csv
â”œâ”€â”€ noticias_larepublica_filtradas.csv
â”œâ”€â”€ noticias_rpp_filtradas.csv
â”œâ”€â”€ noticias_peru21_filtradas.csv
â”œâ”€â”€ noticias_diariocorreo_filtradas.csv
â”œâ”€â”€ noticias_infobae_filtradas.csv
```


Al ejecutarse, el script:

1. Accede a la pÃ¡gina del medio
2. Extrae titulares y enlaces
3. Aplica el filtro de palabras clave
4. Guarda las noticias relevantes en un archivo CSV

## ðŸ“Š Resultado de esta etapa

El resultado del mÃ³dulo de Web Scraping es un conjunto de archivos CSV con noticias policiales recientes, que posteriormente serÃ¡n:

Unificadas en un solo dataset

Procesadas para la extracciÃ³n de ubicaciones

Geocodificadas mediante la API de Nominatim

Visualizadas en un mapa interactivo con Leaflet y OpenStreetMap

## âš ï¸ Consideraciones Ã©ticas y tÃ©cnicas

Se utilizan Ãºnicamente datos de acceso pÃºblico.

El scraping se realiza de forma responsable.

No se realiza ningÃºn tipo de uso comercial de la informaciÃ³n.






>>>>>>> webscraping


